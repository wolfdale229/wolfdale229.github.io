# **100 days of machine learning codes**

## **`To-Do`**

Within the period of 100 days i would read and practice enough data science and machine learning texts to be competent in the subject area. A total of six topics would be studied, with each topic having a total of 16 days study period (subject to how much i read)

**`Things To Learn`**

1. `Numpy` : Numerical computation package in python.

2. `Pandas` : package that contains data structures and data manipulation tools designed to make data
    cleaning and analysis fast and easy in Python

3. `Matplotlib` : Data Visualization package.

4. `Scikit-learn` : It contains a number of state-of-the-art machine learning algorithms.


## **`Resources`**

The following resources would be used for each stage:

**`Books`**
>
    1. Python for Data Analysis.(Wes McKinney)
    2. Python Data Science Handbook. (Jake VanderPlas)
    3. Python Machine Learning,Machine Learning and Deep Learning with Python,scikit-learn, and 
       TensorFlow. (Sebastian Raschka, Vahid Mirjalili )
    4. Hands-on Machine Learning with Scikit-Learn,Keras & TensorFlow.(Aurélien Géron)
    5. Introduction to Machine Learning with Python.(Andreas C. Müller & Sarah Guido)
   
**`Courses`**

1. [Introduction to machine learning](https://www.fast.ai/)(fastai).
2. [Complete Machine Learning and Data Science: Zero to Mastery](https://www.udemy.com/course/complete-machine-learning-and-data-science-zero-to-mastery/)

**`Data Repositories`**

1. [kaggle](https://www.kaggle.com)

2. [UC Irvine Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php)

**`Blogs`**
  
3. [machine learning mastery](https://www.machinelearningmastery.com)

4. [mrdbourke](https://www.mrdbourke.com/)
5. [sebastian raschka](https://sebastianraschka.com/)

**`Software`**

1. Anaconda/jupyter notebook : Anaconda is the standard platform for Python data science, leading in 
    open source innovation for machine learning... [anaconda](https://www.anaconda.com) .
    
2. Goggle Colab : Colaboratory, or "Colab" for short, is a product from Google Research. Colab allows anybody to write and execute arbitrary python code through the browser, and is especially well suited to machine learning, data analysis and education...[google colab](https://research.google.com/colaboratory)

## Day 1 : 18-04-2020

**`Today's Progress`** : Set up a git repository, work through the resource's section and get everything
ready .Learn Numpy's data types and how to create a n-dimensional array.

**Link : ** [DataTypes & N-dimensional array](https://numpy.org/devdocs/user/basics.types.html)

## Day 2 : 19-04-202

**`Today's Progress`** : Numpy arithmetics, basic indexing and slicing.
    
## Day 3 : 20-04-2020

**`Today's Progress`** : Transposing Arrays, swapping Axes and Fast element-wise array (universal function)

## Day 4 : 21-04-2020

**`Today's Progress`** : Mathematical and statistical methods, 

## Day 5 : 22-04-2020

**`Today's Progress`** : Methods for boolean arrays, sorting

## Day 6 : 23-04-2020

**`Today's Progress`** :pandas series and dataframe

## Day 7 - 8 : 25-04-2020

**`Today's Progress`** : Reindexing, Function Application and Mapping, Arithmetic and Data Alignment, Dropping Entries from an Axis

## Day 9 : 26-04-2020

**`Today's Progress`** : Reading and Writing Data in Text Format

## Day 10 : 27-04-2020

**`Today's Progress`** : Overview of Machine Learning

## Day 11 : 28-04-2020

**`Today's Progress`** : End-To-End machine learning project 
> 
    1. Loading the data
    2. Creating Train and Test sets (using stratified sampling)
    3. Exploring the data
        * Visualizing the data
        * Correlation
        * Scatter matrix
        * Normal distribution curve
    
## Day 11 - 12 : 29-04-2020

**`Today's Progress`** : End-To-End machine learning project 
>
    4. Prepare the Data for Machine Learning Algorithms
        * Data cleaning
                - SimpleImputer() class
                - Dropna()
                - drop()
                - fillna()     
        * Handling text and categorical attributes
                - OrdinalEncoder() class
                - OneHotEncoder() class
                - Pipeline() class
                - ColumnTranformer() class
         
## Day 12 - 13 : 30-04-2020

**`Today's Progress`** : End-To-End machine learning project 
>
    4. ... Continue
        * Handling text and categorical attributes
                - Pipeline() class
                - ColumnTranformer() class
                - StandardScaler()
    5. Select and Train a Model
        * Training and Evaluating on the Training Set
                - Linear regression 
                - Decision Tree
                - RandomForest Regressor
        * Better Evaluation Using Cross-Validation
                - cross_val_score()
        * Fine-Tune Your Model
       
## Day 13 - 14 : 1-05-2020

**`Today's Progress`** : End-To-End machine learning project
>
    5. ... Continue
                - Randomized Search
                - Grid Search
                - Ensemble method
                - Manual method
         * Feature importance (randomForest algorithm)
         * Evaluate Your System on the Test Set
         * Launch, Monitor, and Maintain The System
         
## Day 15 : 2-05-2020

**`Today's Progress`** : End-To-End machine learning exercises
>
    1. Try using Support Vector Machine regressor
    2. Replace GridSearchCV with RandomSearchCV
    3. Create a Pipeline

## Day 16 : 3-05-2020

**` Today's Progress`** : Classification (MNIST dataset); Binary Classifiction
>
    1. Training a Binary Classifier
    2. Performance Measures (binary classifier)
        - Measuring Accuracy Using Cross-Validation
        - Confusion Matrix
        - Precision and Recall
        - F1 Score
        - Precision/Recall Trade-off
        - The ROC Curve

## Day 16 - 17 : 4-05-2020

**`Today's Progress`** : Classification; Multiclass Classification
>
    1. Training a Multiclass Classifier

## Day 18 : 5-5-2020

**`Today's Progress`** : Classification : Error Analysis (Found Error analysis confusing, noted for further reading )
>
    1. Error analysis
    2. chapter 3 exercises (started)

## Day 18 - 19 : 6-5-2020

**`Today's Progress`** : Chapter 3 exercises
>
    1. Use KNeighborsClassifier to get a score of 97%
    2. Titanic dataset

## Day 20 - 21: 7-05-2020

**`Today's Progress`** : Linear Regressions
>
    1. What is a Linear Regression
    2. Calculating a Linear Regression 
        *. Normal Equation (method 1)
        *. Gradient Descent (method 2)

## Day 22 : 8-5-2020

**`Today's Progress`** : Linear Regressions (continuation)
>
        *. Mini-batch Gradient Descent
        *. Stochastic Gradient Descent
    3. polynomial Regression
      
## Day 23 : 9-05-2020

**`Today's Progress`** : Chapter 3 exercises, Linear Model
>
    1. Polynomial Regression
    2. Learning Curves
    3. Regularized Linear Models
    
## Day 24-25 : 10/11-05-2020

**`Today's Progress`** : Linear Model and implementation
>
    1. Ridge Regression
    2. Lasso Regression
    3. Early Stopping
    4. Logistic Regression
    5. Softmax Regression
        
## Day 26 : 12/13-05-2020

**`Today's Progress`** Read the get started section of the scikit-learn doc and practiced building some models
>
    1. Practice (Predictiing the price of used fiat automobiles)
    2. Reading scikit-learn doc (Getting started section)
    3. Practice (predicting the quality of wine)
        
## Day 27 : 12/13-05-2020

**`Today's Progress`** : Support vector machines  

## Day 28 : 14-05-2020

**`Today's Progress`** : Linear SVM classifier

## Day 29 : 15-05-2020

**`Today's Progress`** Done with support vector machines

## Day 30 : 16-05-2020

**`Today's Progress`** : Looking at Decision tree and how to implement them using sklearn
>
    1. [Decision tree from scratch](https://r2---sn-i3b7knl6.googlevideo.com/videoplayback?expire=1589601694&ei=PhG_Xs3iC8eR-gbt1LT4BQ&ip=123.16.150.42&id=o-ALauN0Ti66dcaa29L8vJ9TegCgA5KpDOJBk53UioVJAZ&itag=22&source=youtube&requiressl=yes&vprv=1&mime=video%2Fmp4&ratebypass=yes&dur=592.062&lmt=1540157856275889&fvip=7&fexp=23882514&c=WEB&txp=5431432&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cvprv%2Cmime%2Cratebypass%2Cdur%2Clmt&sig=AOq0QJ8wRQIgDb9mQLtwkj7G_FNGW13njq9lfG8pdCE77_x40ZbsuSoCIQCeGf7Nuc_pkM6WNSy0IbAcRq9eb6veM_VlvvkFIOqDeQ%3D%3D&contentlength=32934629&video_id=LDRbO9a6XPU&title=Let%E2%80%99s+Write+a+Decision+Tree+Classifier+from+Scratch+-+Machine+Learning+Recipes+%238&rm=sn-8qj-i5ozd7k,sn-8qj-i5oer7k&req_id=9ba6c214ecd3a3ee&ipbypass=yes&redirect_counter=2&cms_redirect=yes&mh=TF&mm=30&mn=sn-i3b7knl6&ms=nxu&mt=1589589380&mv=m&mvi=1&pl=21&lsparams=ipbypass,mh,mm,mn,ms,mv,mvi,pl&lsig=AG3C_xAwRgIhAK_lCOXFjB3EGro4L3lyTYDPexw7JNYLutJVhF4m7FxlAiEAlS1SrOiuDzwD0MsAkUA_A-9rApBJ0n5i1msMRcq9E_I%3D)
    2. Exercise (not all)
    3. Hardware regression problem (Predicting the estimated relative performance).

## Day 31 : 17-05-2020

**`Today's Progress`** : Ensemble Learning and Random Forests
>
    1. Voting Classifier
    2. Bagging and Pasting
    3. Out-of-bag Evaluation
    4. Random Forest
            
## Day 32 : 18-05-2020

**`Today's Progress`** continuation of the Ensemble models
>
    1. Extra Trees
    2. exercises 
Note : Still need to learn stacking method and blending
        
## Day 33 : 19-05-2020

**`Today's Progress`** : Dimensionality Reduction
>
    1. Making a regression model to predict the quality of wine using the [wine quality dataset] (http://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009)
    2. Principal component analysis
Note : i did not understand this topic, come back to it later.

## Day 34 : 20-05-2020

**`Today's Progress`** : Learning Model Evaluation and Improvement
>
    1. Cross validation 
        * K-fold
        * Stratified K-Fold
        * Leave-one-out 
        * shuffle-split 

## Day 35 : 21-05-2020

**`Today's Progress`** : Learning ways to eveluate models
>
    1. Grid Search
        * Grid search with cross validation
        * GridSearchCv estimator
        
**`End of my first 35 days of learning, i won't learn deep learning now would have another go at machine learning to really understand it. This time i would be using the fastai intriduction to machine learning course and python machine learning book.`**

## Day 36 : 22-05-2020

**`Today's Progress`** : Today is about ways of measuring binary classification models using various metrics
>
    1. fi_score
    2. Recall
    3. Precision
    4. confusion metrics
    5. kind of errors
    6. inbalanced data

## Day 37 : 23-05-2020

**`Today's Progress`** : Learning how to use the Ipython software
>
    1. magic function
    2. copying, pasteing, running python program

## Day 38 : 24-05-2020

**`Today's Progress`** : learnt some advance python concepts (data structures).
>
    1. list comprehension
    2. generator expression 
    3. namedtuples

## Day 39 : 25-05-2020

**`Today's Progress`** : Learning the basics of numpy
>
    1. creating an array 
    2. Basic operations
    3. Reshaping
    4. Slicing, Indexing, copying
    5. Array Concatenation
        * stack
        * vstack
        * hstack
    6. splitting
        * split
        * vsplit
        * hsplit
    7. Numpy computation (universal function)
        * Additions
        * subtraction
        * trigonometris
        * exponential
        
## Day 40 : 26-05-2020

**`Today's Progress`** : Numpy
> 
    1. Aggregates 
        * sum
        * min
        * max
        * mean
        * median
        * std
        * all
        * percentile .....
    2. Working examples using numpy aggregates

## Day 41 : 27-05-2020

**`Today's Progress`** : Today would be the beginning of learning about data manipulation with pandas
>
    1. Series
        * indexing
        * creating a pd Series object from a dictionary
    2. DataFrame
    3. iloc, loc
   
## Day 42 : 28-05-2020

**`Today's Progress`** : continuation of  the pandas library and oerating on datas in pandas
>
    1. ufunc operations on a DataFrame object
    2. Handling missing data.
        * dropna()
        * fillna()
        * isnull()
        * notnull()
    3. Hierarchical Indexing
        
## Day 43 : 29-05-2020

**`Today's Progress`** : still learning about the Pandas library
>
    1. aggregation and grouping
        methods:
        * count()
        * mean(), median()
        * first(), last()
        * std(), var()
        * prod()
        * sum()
        * min(), max()

## Day 44 : 30-05-2020

**`Today's Progress`** : learning aggregate, filter, transform and apply methods in Pandas.
>
    1. pivot table
    2. Vectorized string operations
    3. Methods using regular expressions
    
## Day 45 : 31-05-2020

**`Today's Progress`** : reading about time series analysis in Pandas
>
    1. Time series data
    2. Dates and times in Pandas: Best of both worlds
    3. Indexing, Selecting, subsetting
    
## Day 46 : 1-06-2020

**`Today's Progress`** : Visualization with Matplotlib and Seaborn.
>
    1. Simple plot
    2. Adjusting the plot : Line Color and Style
    3. Adjusting the plot : Axes Limits

## Day 47 : 2-06-2020

**`Today's Progress`** : continuation of data visualization with matplotlib
>
    1. Labeling Plots
    2. Scatter plots(plt.plot and plt.scatter)
    3. Changing size, color, and transparency in scatter points
    4. Histograms, Binning, and Density
       
 ## Day 48 : 3-06-2020

 **`Today's Progress`** : Learning what machine learning is, the types, terminology and notations.
 >
     1. implementing a perceptron algorithm    
     
## Day 49 : 4-06-2020

**`Today's Progress`** : Adaptive linear neurons
>
    1. implementing Adaline in python 
    2. Machine learning classifiers using scikit-learn
       
## Day 50-51 : (5-6)-06-2020

**`Today's Progress`** : still learning classifiers using sklearn, Data preprocessing
>
    1. Modeling class probabilities via Logistic Regression
    2. Support Vector Machines
    3. Decision tree
    4. Dealing with missing values
    5. Handling categorical values
    6. One Hot Encoding
    7. Label Encoding
    8. Partitioning a dataset into separate training and test datasets
    9. Feature scaling
    10. feature selection 

## Day 52 : 7-06-202

**`Today's Progress`** : Still on preprocessing data for machine learning
>
    1. feature importtance in Random Forest 
    2. Dimentionality reduction 
       
## Day 53 : 8-06-2020

**`Today's Progress`** : Still on dimensionality reduction 
>
    1. principal component analysis
    2. kernel PCA
    
## Day 54-55 : (9-10)-06-2020

**`Today's Progress`** : Regression analysis, What is a regression model
>
    1. simple linear regression
    2. Multiple linear regression 
    3. Exploratory Data Analysis
    4. Implementing an ordinary least squares linear regression model

## Day 56 : 11-06-2020

**`Today's Progress`** : Redoing Dimensionality reduction, different types of principal component analysis method
>
    1. Principal component analysis
    2. Singular value decomposition(SVD)
    3. Randomized PCA

learning about Unsupervised learning techniques

## Day 57 : 12-06-2020

**`Today's Progress`** : Finishing up on Unsupervised learning.
NOTE : I would re-read this topic again and python machine learning book would benefit does who are good in mathematics.
>
    1. Clustering
    2. Using Clustering for Preprocessing
    3. DBSCAN

**`Starting the Fastai's Intro to Machine Learning course today and i'd be using the Introduction to Machine Learning with Python.(Andreas C. Müller & Sarah Guido) book as a companion to the course. I'm setting aside a week for each topic in the course, this would entail:`**

**Book(s):** Introduction to Machine Learning with Python.(Andreas C. Müller & Sarah Guido)

**Course:** Fastai, Introduction to Machine Learning.(Jeremy Howard & Rachel Thomas)

**Steps:**
>
    1. Watch a course video and jot down concepts.
    2. Read up on what i have jotted down and read about machine learning.
    3. Watch the video again and work through the example.
    4. Implement the lecture's idea without the help of the video 
    5. Biuld a project (work on a data set) based on what i have learnt.
    6. Write a blog on what i have learnt so far.

**Note :**Step 1-6 would be done per-week (approx).
       
## Day 58 : 13-06-2020

**`Today's Progress`** : Reading about machine learning in general and what i jotted down from the lecture video
> 
    1. Working on the iris dataset
       
## Day 59 : 15-06-2020

**`Today's Progress`** 
>
    1. What is supervised learning
    2. Types of supervised learning 
    3. Generalization, Overfitting, and Underfitting
    4. K-Nearest Neighbors
       
## Day 60 : 16-06-2020

**`Today's Progress`** 
>
    1. Watching and working through lessons 1 of the fastai lecture
       
## Day 61 : 17-06-2020

**`Today's Progress`**
> 
    1. Reading about Linear Models
       
## Day 62 : 18-06-2020

**`Today's Progress`** : I would take a break, reinstall anaconda and set up fastai.v0.7 and fastai.v3 environmaents properly. Shit seems to be messed up.
>
    1. Reinstall anaconda and extensions
    2. Create a conda environment for fastai v0.1 (Introduction to machine learning)
    3. Create a conda envirment for fastai v3
    4. Building a RandomforestRegression forest of the blue book for bulldozers dataset with looking (and using) at the fastai  
       code.
       
## Day 62 : 19-06-2020


## Day 63 : 20-06-2020

**`Today's Progress`** : Refreshing my python knowledge 

## Day 64 : 21-06-2020

**`Today's Progress`** : Watching lecture 2 of the fastai introductfion to machine learning course, work on some pandas exercises and keep refreshing my python skills
       
## Day 65 : 22-06-2020

**`Today's Progress`** : Learning about decision trees, work on some pandas execises and learning regular expression in python 
       
## Day 66 : 23-06-2020

**`Today's Progress`** : Doing some Exploratory data analysis, pandas exerice, building a random forest model using the fastai library, complete the Decision tree reading.

## Day 67 : 24-06-2020

**`Today's Progress`** : Worked on the titanic dataset, completing decision trees.

## Day 68 : 25-06-2020

**`Today's Progree`** : working through the second lecture, working on some pandas exercise.
       
       
       
       
       
       
       
       
       
        
        
        
        
        
        